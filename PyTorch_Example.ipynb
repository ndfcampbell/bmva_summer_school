{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5y7O9fs7RvH",
        "outputId": "8c5e25c3-9b2d-4f44-c185-9729a477f917"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Collecting torch\n",
            "  Downloading torch-2.3.1-cp310-cp310-manylinux1_x86_64.whl (779.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.1/779.1 MB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.18.0+cu121)\n",
            "Collecting torchvision\n",
            "  Downloading torchvision-0.18.1-cp310-cp310-manylinux1_x86_64.whl (7.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m48.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchviz\n",
            "  Downloading torchviz-0.0.2.tar.gz (4.9 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting tensorboardcolab\n",
            "  Downloading tensorboardcolab-0.0.22.tar.gz (2.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Collecting triton==2.3.1 (from torch)\n",
            "  Downloading triton-2.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.1/168.1 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m46.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from torchviz) (0.20.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Building wheels for collected packages: torchviz, tensorboardcolab\n",
            "  Building wheel for torchviz (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchviz: filename=torchviz-0.0.2-py3-none-any.whl size=4132 sha256=0bad712259f8452b3aaf99746fc5610e5fb8897d5fda4c0ff9c7d424fa5e18c3\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/97/88/a02973217949e0db0c9f4346d154085f4725f99c4f15a87094\n",
            "  Building wheel for tensorboardcolab (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tensorboardcolab: filename=tensorboardcolab-0.0.22-py3-none-any.whl size=3832 sha256=5ea645f5c4b600a9e91ca690ab0bfa71125a88fa9ec1488c090ef45cb56c6cef\n",
            "  Stored in directory: /root/.cache/pip/wheels/8d/ee/46/7fe2bbbf1edbcfeabfaf13962dcaadec1f631d11147fd9d34d\n",
            "Successfully built torchviz tensorboardcolab\n",
            "Installing collected packages: tensorboardcolab, triton, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchviz, torchvision\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 2.3.0\n",
            "    Uninstalling triton-2.3.0:\n",
            "      Successfully uninstalled triton-2.3.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.3.0+cu121\n",
            "    Uninstalling torch-2.3.0+cu121:\n",
            "      Successfully uninstalled torch-2.3.0+cu121\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.18.0+cu121\n",
            "    Uninstalling torchvision-0.18.0+cu121:\n",
            "      Successfully uninstalled torchvision-0.18.0+cu121\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.3.0+cu121 requires torch==2.3.0, but you have torch 2.3.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 tensorboardcolab-0.0.22 torch-2.3.1 torchvision-0.18.1 torchviz-0.0.2 triton-2.3.1\n"
          ]
        }
      ],
      "source": [
        "# Standard numpy for matrices, vectors, etc..\n",
        "import numpy as np\n",
        "\n",
        "# Visualisation (plotting, etc..)\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "try:\n",
        "    in_colab = False\n",
        "    import google.colab\n",
        "    in_colab = True\n",
        "except:\n",
        "    pass\n",
        "\n",
        "# Use the following to access torch and tensorboard when running on colab\n",
        "if in_colab:\n",
        "    !pip install -U torch torchvision torchviz tensorboardcolab\n",
        "    from tensorboardcolab import *\n",
        "\n",
        "# New for today! Import PyTorch (refered to by package name torch)\n",
        "import torch\n",
        "\n",
        "# This is used for graph visualisation..\n",
        "from torchviz import make_dot\n",
        "\n",
        "# Please see the following page for getting\n",
        "# started guide and tutorials:\n",
        "# \u0016\u0016https://pytorch.org/tutorials/index.html"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Standard numpy\n",
        "\n",
        "Let's start with a simple recap of what we are used to with standard numpy in python.."
      ],
      "metadata": {
        "id": "EOjyA_Z6upF6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9__IpqO7RvL",
        "outputId": "b0d6144d-c9d4-493b-b225-97a5003e896a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In numpy:\n",
            "a =  [1. 2. 3.]\n",
            "a =  [2. 2. 2.]\n",
            "a + b =  [3. 4. 5.]\n",
            "a ** b =  [1. 4. 9.]\n",
            "c = (a + b) * (a ** b) =  [ 3. 16. 45.]\n"
          ]
        }
      ],
      "source": [
        "# What we are used to in standard nummerical programming:\n",
        "\n",
        "a = np.array([1.0, 2.0, 3.0])\n",
        "\n",
        "b = np.array([2.0, 2.0, 2.0])\n",
        "\n",
        "a_plus_b = a + b\n",
        "\n",
        "a_power_b = a ** b\n",
        "\n",
        "c = a_plus_b * a_power_b\n",
        "\n",
        "print('In numpy:')\n",
        "print('a = ', a)\n",
        "print('a = ', b)\n",
        "print('a + b = ', a_plus_b)\n",
        "print('a ** b = ', a_power_b)\n",
        "print('c = (a + b) * (a ** b) = ', c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ksIh9vuA7RvO",
        "outputId": "753afae8-0a79-4e4a-8bd6-aae0022d1836"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In torch:\n",
            "a =  tensor([1., 2., 3.], dtype=torch.float64)\n",
            "a =  tensor([2., 2., 2.], dtype=torch.float64)\n",
            "a + b =  tensor([3., 4., 5.], dtype=torch.float64)\n",
            "a ** b =  tensor([1., 4., 9.], dtype=torch.float64)\n",
            "c = (a + b) * (a ** b) =  tensor([ 3., 16., 45.], dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "# Let's do this with pytorch (or just torch):\n",
        "#\n",
        "# (Using t_ to denote torch variables - this is optional and just for clarity)\n",
        "#\n",
        "\n",
        "t_a = torch.tensor(a)\n",
        "\n",
        "t_b = torch.tensor(b)\n",
        "\n",
        "t_a_plus_b = t_a + t_b\n",
        "\n",
        "t_a_power_b = t_a ** t_b\n",
        "\n",
        "t_c = t_a_plus_b * t_a_power_b\n",
        "\n",
        "print('In torch:')\n",
        "print('a = ', t_a)\n",
        "print('a = ', t_b)\n",
        "print('a + b = ', t_a_plus_b)\n",
        "print('a ** b = ', t_a_power_b)\n",
        "print('c = (a + b) * (a ** b) = ', t_c)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### So why would we use torch instead of numpy?\n",
        "\n",
        "So far, the two seem to operate in the same manner so why do we need torch?\n",
        "\n",
        "In the background, torch is also builds a computational graph of the operations being performed. This will allow, amongst other things, the graph to be analysed and gradients to be computed automatically by going backwards through the graph applying the differentiation **chain rule** to propagate gradient information.\n",
        "\n",
        "*Let's see an example in action!*\n",
        "\n",
        "#### Aside: More information about pytorch autograd:\n",
        "\n",
        "- [Automatic Differentiation with torch.autograd](https://pytorch.org/tutorials/beginner/basics/autogradqs_tutorial.html)\n",
        "\n",
        "- [Autograd Mechanics](https://pytorch.org/docs/stable/notes/autograd.html)"
      ],
      "metadata": {
        "id": "hcTzKahK8W22"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's do the same calculation as before but we will tell torch that we would\n",
        "# like to calculate gradients by using the \"requires_grad=True\" argument when\n",
        "# we create the pytorch tensors..\n",
        "\n",
        "t_a = torch.tensor(a, requires_grad=True)\n",
        "\n",
        "t_b = torch.tensor(b, requires_grad=True)\n",
        "\n",
        "t_a_plus_b = t_a + t_b\n",
        "\n",
        "t_a_power_b = t_a ** t_b\n",
        "\n",
        "t_c = t_a_plus_b * t_a_power_b\n",
        "\n",
        "print('t_c = ', t_c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LhgNc5eE8PDf",
        "outputId": "decccb61-fd21-4f8d-c2b4-1ac4ffbcca0a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t_c =  tensor([ 3., 16., 45.], dtype=torch.float64, grad_fn=<MulBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### We notice t_c has a new attribute!\n",
        "\n",
        "If we look the printed output for t_c we notice there is a new piece of information, now t_c has an attribute called \"grad_fn\".\n",
        "\n",
        "This indicates that there is a function associated with the tensor to propagate the gradient backward (part of the *computational graph* we mentioned before).\n",
        "\n",
        "We notice that the grad_fn object is of type **MulBackward** which indicates that this is a function that calculates the gradient through a multiplication operation. We remember that t_c is the result of a multiplication:\n",
        "`t_c = t_a_plus_b * t_a_power_b`\n",
        "so we would expect the gradient to require an application of the chain rule via the derivative of a multiplication operation.\n"
      ],
      "metadata": {
        "id": "ErYHlyY8AZN2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We can visualise the computational graph for all the relevant terms:\n",
        "\n",
        "print('t_c gradient function = ', t_c.grad_fn)\n",
        "print('t_a_plus_b gradient function = ', t_a_plus_b.grad_fn)\n",
        "print('t_a_power_b gradient function = ', t_a_power_b.grad_fn)\n",
        "print('t_b gradient function = ', t_b.grad_fn)\n",
        "print('t_a gradient function = ', t_a.grad_fn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JgRPajy18PY8",
        "outputId": "e0551851-baa0-4514-8fc9-2b7f8fb9d6a4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t_c gradient function =  <MulBackward0 object at 0x7b554e1ce0e0>\n",
            "t_a_plus_b gradient function =  <AddBackward0 object at 0x7b554e1cded0>\n",
            "t_a_power_b gradient function =  <PowBackward1 object at 0x7b554e1ce0e0>\n",
            "t_b gradient function =  None\n",
            "t_a gradient function =  None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We note that when we get to t_a and t_b we no longer have any gradient functions since these are the starting points of the calculation (and not dependent on any other values).\n",
        "\n",
        "Otherwise, we can see that a gradient function is associated with each operation using a suitable function. So t_a_plus_b has **AddBackward** since it is the result of an addition operation. Equally, t_a_power_b has **PowBackward** since it is the result of taking a to the power of b.\n",
        "\n",
        "**We can now see these gradient functions in action!** We will now make use of the gradient functions by running the *backward* operation in torch which tells the computational graph to propagate gradients.\n",
        "\n",
        "Let us calculate the gradients of sum(t_c) wrt t_a and t_b. That is we want\n",
        "$$\n",
        "\\frac{d s}{d \\mathbf{a}} \\quad \\text{and} \\quad \\frac{d s}{d \\mathbf{b}}\n",
        "$$\n",
        "where $s = \\sum_i c_i$."
      ],
      "metadata": {
        "id": "USrUraRQBvzb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a result to hold the scalar sum\n",
        "t_s = torch.sum(t_c)\n",
        "\n",
        "# Propagate gradients for t_s by calling backward..\n",
        "t_s.backward()\n",
        "\n",
        "# Now we can read out the gradients..\n",
        "print('Gradient for t_a (ds/da) = ', t_a.grad)\n",
        "print('Gradient for t_b (ds/db) = ', t_b.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8xNGhnJCuTr",
        "outputId": "d055ac25-46d4-4599-abe5-2b474b00975d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient for t_a (ds/da) =  tensor([ 7., 20., 39.], dtype=torch.float64)\n",
            "Gradient for t_b (ds/db) =  tensor([ 1.0000, 15.0904, 58.4376], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's check that these results make sense.\n",
        "\n",
        "We have the following:\n",
        "$$\n",
        "s = \\sum_i c_i, \\quad c_i = (a_i + b_i) \\times {a_i}^{b_i}\n",
        "$$\n",
        "\n",
        "Now if we remember our calculus rules, we will need to apply the following identities (we will assume we have functions $a(x)$ and $b(x)$ since we are thinking about *propagating* gradients):\n",
        "$$\n",
        "\\begin{aligned}\n",
        "\\text{Sum Rule:}&&\\quad\\frac{d}{dx} (a+b) &= \\frac{da}{dx} + \\frac{db}{dx}\n",
        "\\\\\n",
        "\\text{Product Rule:}&&\\quad\\frac{d}{dx} (a \\times b) &= \\frac{da}{dx} \\times b + a \\times \\frac{db}{dx}\n",
        "\\\\\n",
        "\\text{Power Rule:}&&\\quad\\frac{d}{dx} (x^a) &= a \\times x^{a - 1}\n",
        "\\end{aligned}\n",
        "$$\n",
        "The final exponent rule (needed for t_b) is a little more involved:\n",
        "$$\n",
        "\\text{Exponent Rule:}\\quad\\frac{d}{dx} (a^b) =\n",
        "\\frac{d}{dx} (e^{b \\ln a}) =\n",
        "(e^{b \\ln a}) \\frac{d}{dx} (b \\ln a) =\n",
        "a^b \\left( \\frac{db}{dx} \\ln a + \\frac{da}{dx} \\frac{b}{a} \\right)\n",
        "$$\n",
        "\n",
        "So, we can mimic the work of torch for t_a:\n",
        "\n",
        "$$\n",
        "\\frac{d c_i}{da_i}\n",
        "  = \\frac{d}{da_i} [(a_i + b_i) \\times {a_i}^{b_i}]\n",
        "  = {a_i}^{b_i} \\times \\left[\\frac{d}{da_i} (a_i + b_i)\\right]\n",
        "  + (a_i + b_i) \\times \\left[\\frac{d}{da_i} ({a_i}^{b_i}) \\right]\n",
        "$$\n",
        "$$\n",
        "\\Rightarrow \\frac{d c_i}{da_i}\n",
        "  = {a_i}^{b_i} + (a_i + b_i) \\times (b_i \\times {a_i}^{b_i - 1})\n",
        "$$\n",
        "\n",
        "**Let's check the pytorch result..**"
      ],
      "metadata": {
        "id": "aqTk4s7xFeKQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate our hand-derived gradient for t_a..\n",
        "\n",
        "t_dc_da = (t_a ** t_b) + (t_a + t_b) * t_b * (t_a ** (t_b - 1.0))\n",
        "\n",
        "print('Check t_dc_da = ', t_dc_da)\n",
        "\n",
        "print('Torch Gradient for t_a = ', t_a.grad)\n",
        "\n",
        "# Hopefully these two match!!"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5G4XmmLpCvCE",
        "outputId": "1083661f-d3bb-4c0a-e5b3-02026703da69"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Check t_dc_da =  tensor([ 7., 20., 39.], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "Torch Gradient for t_a =  tensor([ 7., 20., 39.], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVPXgcGr7RvX"
      },
      "source": [
        "### So it seems to work!\n",
        "\n",
        "If you would like you can check the result for t_b as well..\n",
        "\n",
        "Note: This is a more involved derivation (due to the more complex exponential rule); we can already see that even for our simple calculation, the gradient derivations can get very involved and so hand-calculation is error prone, time consuming and has to be changed with every modification to the original calculation. *The automatic differentiation in torch is really helping out!*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0wunnT57RvY"
      },
      "source": [
        "### Why do we need to calculate derivatives?\n",
        "\n",
        "Well, what if we are doing a (gradient based) optimistion? Let's see a full motivating example..\n",
        "\n",
        "## Example: fitting the parameters of a distribution\n",
        "\n",
        "Suppose we want to fit a Gaussian distribution $\\mathsf{N}(\\mu, \\sigma^2)$ to a set of numbers $X = \\{ x_0, x_1, \\dots, x_{N-1} \\}$.\n",
        "\n",
        "**We know that this fit can actually be calculated directly (one of the nice properties of the Gaussian distribution) but we will pretend that we cannot determine these parameters in closed-form and will perform nummerical optimisation to determine them - this way we can check our results with the analytic solution!**\n",
        "\n",
        "If we assume the numbers are i.i.d. (indentically and independently distributed) samples from a Gaussian then the likelihood of $X$ is given by:\n",
        "\n",
        "\\begin{align}\n",
        "p(X) &= p(x_0) \\cdot p(x_1) \\cdot \\dots \\cdot p(x_{N-1}) \\\\\n",
        " &= \\mathsf{N}(x_0 \\,|\\, \\mu, \\sigma^2) \\cdot \\mathsf{N}(x_1 \\,|\\, \\mu, \\sigma^2) \\cdot \\dots \\cdot \\mathsf{N}(x_{N-1} \\,|\\, \\mu, \\sigma^2) \\\\\n",
        " &= \\prod_{n=0}^{N-1} \\mathsf{N}(x_{n} \\,|\\, \\mu, \\sigma^2) \\\\\n",
        " &= \\prod_{n=0}^{N-1} \\frac{1}{\\sqrt{2\\pi\\sigma^2}}\n",
        "    \\exp{\\left( - \\frac{(x_{n} - \\mu)^2}{2\\sigma^2} \\right)}\n",
        "\\end{align}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RP90UPyS7RvY"
      },
      "source": [
        "**Top Tip!** When working with exponential family of distributions it often helps to work in the log domain..\n",
        "\n",
        "\\begin{align}\n",
        "\\log  p(X)  &= \\sum_{n=0}^{N-1}\n",
        "    -\\frac{1}{2} \\log{\\left( 2\\pi\\sigma^2 \\right)}\n",
        "    -\\frac{(x_{n} - \\mu)^2}{2\\sigma^2}\n",
        "\\end{align}\n",
        "\n",
        "So, we have the *maximum likelihood* fit to the parameters when we find the values of $\\mu$ and $\\sigma^2$ that maximise $p(X)$ which (since $\\log\\,(\\cdot)$ is a concave function) occurs at the same time that $\\log p(X)$ is maximised."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "573itA7E7RvY"
      },
      "source": [
        "In our case we can find an analytic solution for\n",
        "\n",
        "\\begin{align}\n",
        "\\mu^{*} &= {\\arg\\max}_{\\mu} \\, \\log p(X) \\\\\n",
        "{\\sigma^{*}}^2 &= {\\arg\\max}_{\\sigma^2} \\, \\log p(X) \\\\\n",
        "\\end{align}\n",
        "\n",
        "But let's pretend that the problem was more complicated and we needed to use *optimisation* to solve the problem.."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kuD00Gg97RvZ"
      },
      "source": [
        "To perform numerical optimisation we need to be able to calculate gradients of the objective function ($\\log p(X)$) wrt the parameters that you are optimising ($\\mu$ and $\\sigma^2$).\n",
        "\n",
        "*Let's see how to do this in torch..*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "8VYhQuth7RvZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6284d96-a468-4a52-dc32-795ce19f5430"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X = \n",
            " [0.884 4.165 0.03  5.279 1.645 2.308 2.365 2.898 0.868 1.62  2.721 3.023 3.93  2.062 0.676 5.51\n",
            " 1.135 2.444 2.592 3.984]\n"
          ]
        }
      ],
      "source": [
        "# First let's generate some numbers to fit the data to..\n",
        "\n",
        "# How many values of x?\n",
        "N = 20\n",
        "\n",
        "# Pick the real mean and variance..\n",
        "mu_true = 2.5\n",
        "sigma_true = 1.5\n",
        "\n",
        "x_n = np.random.normal(mu_true, sigma_true, N)\n",
        "\n",
        "np.set_printoptions(precision=3, linewidth=100)\n",
        "print('X = \\n', np.transpose(x_n))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRMsdGeW7Rvb"
      },
      "source": [
        "We are now going to create our implicit torch computation graph but we are going to account for the fact that $\\mu$ and $\\sigma^2$ are no longer constants since we wish to vary their values to find the maximum of $\\log p(X)$. With numerical optimisation, we need to start with a guess for the values of $\\mu$ and $\\sigma^2$; in this case, we will start with\n",
        "\\begin{align}\n",
        "\\mu_{\\mathrm{initial}} &= 1\\\\\n",
        "\\sigma^2_{\\mathrm{initial}} &= 1\n",
        "\\end{align}\n",
        "\n",
        "**Top Tip!** Care needs to be taken with $\\sigma$ since it can only be a positive value (unlike $\\mu$ which can be any real number). In general, `torch` variables can be positive or negative. In this example we square the value of `t_sigma` before using it to ensure that `t_sigma_2` is a positive value but we shouldn't, therefore, use the value for `t_sigma` directly in calculations..\n",
        "\n",
        "As a reminder, we want to find:\n",
        "\\begin{align}\n",
        "\\log  p(X)  &= \\sum_{n=0}^{N-1}\n",
        "    -\\frac{1}{2} \\log{\\left( 2\\pi\\sigma^2 \\right)}\n",
        "    -\\frac{(x_{n} - \\mu)^2}{2\\sigma^2}\n",
        "%    \\\\\n",
        "%    &=  -\\frac{N}{2} \\log{\\left( 2\\pi\\sigma^2 \\right)}\n",
        "%    - \\frac{1}{2\\sigma^2} \\sum_{n=0}^{N-1}\\left(x_{n} - \\mu\\right)^2\n",
        "\\end{align}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "G6WvLLpj7Rvb"
      },
      "outputs": [],
      "source": [
        "# Our initial guesses..\n",
        "mu_initial_guess = 1.0\n",
        "sigma_initial_guess = np.sqrt(1.0)\n",
        "\n",
        "# The data to fit to (NOTE: this is our constant data so no gradients required)\n",
        "t_x_n = torch.tensor(x_n)\n",
        "\n",
        "# Note: mu and sigma are now *variables* not constants!\n",
        "# We need to specify their data type and initial value..\n",
        "t_mu = torch.tensor(mu_initial_guess, requires_grad=True)\n",
        "t_sigma = torch.tensor(sigma_initial_guess, requires_grad=True)\n",
        "\n",
        "# Note: this step is important - don't use t_sigma directly!!\n",
        "t_sigma_2 = t_sigma ** 2.0\n",
        "\n",
        "# Calculate log p(X) terms..\n",
        "\n",
        "t_x_minus_mu_2 = (t_x_n - t_mu) ** 2.0\n",
        "t_denom = 2.0 * t_sigma_2\n",
        "t_sigma_term = - 0.5 * torch.log(2.0 * np.pi * t_sigma_2)\n",
        "\n",
        "t_log_P_terms = t_sigma_term - (t_x_minus_mu_2 / t_denom)\n",
        "\n",
        "# The sum is performed by a reduction in torch\n",
        "# (since a vector goes in and a scalar comes out)\n",
        "# but this is effectively the same as np.sum(...)\n",
        "t_log_P = torch.sum(t_log_P_terms)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "0Q8s9IZc7Rvd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "913ecfa0-1985-4914-cac9-8df65c68a572"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Torch log p(X) =  tensor(-68.4921, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "(using initial guesses for mu and sigma)\n",
            "\n",
            "Value from scipy stats package =  -68.4921329611185\n",
            "\n",
            "Everything working!\n"
          ]
        }
      ],
      "source": [
        "# Let's just check that we calculated things correctly:\n",
        "\n",
        "print('Torch log p(X) = ', t_log_P)\n",
        "print('(using initial guesses for mu and sigma)\\n')\n",
        "\n",
        "# Check with scipy..\n",
        "from scipy.stats import norm\n",
        "check_value = np.sum(norm.logpdf(x_n,\n",
        "                                 mu_initial_guess,\n",
        "                                 sigma_initial_guess))\n",
        "print('Value from scipy stats package = ', check_value)\n",
        "\n",
        "# Check these are close (to nummerical precision - remember not to use\n",
        "# equality when checking floating point numbers due to round-off error)..\n",
        "assert(np.isclose(t_log_P.detach().numpy(), check_value))\n",
        "\n",
        "print('\\nEverything working!')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NOTE:** torch.tensor values are not the same as numpy.arrays and so when passing torch values into numpy functions (as illustrated in the np.isclose call above). If we have a value that is currently associated with a computational graph to calculate the gradient then we must also create a copy first by detaching it from the graph, hence the use of\n",
        "`t_log_P.detach().numpy()`\n"
      ],
      "metadata": {
        "id": "nCk8x3aSPXZU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### This is great, but what if we want to use different parameter values?\n",
        "\n",
        "Well, we need to put our torch code into a function so that we can call it with different values. Let's put the code from above into a function:"
      ],
      "metadata": {
        "id": "kQEWcNdgQNMa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the log likelihood function taking the data and parameters as arguments\n",
        "def torch_gaussian_log_likelihood(t_x_n, t_mu, t_sigma):\n",
        "    # Note: this step is important - don't use t_sigma directly!!\n",
        "    t_sigma_2 = t_sigma ** 2.0\n",
        "\n",
        "    # Calculate log p(X) terms..\n",
        "\n",
        "    t_x_minus_mu_2 = (t_x_n - t_mu) ** 2.0\n",
        "    t_denom = 2.0 * t_sigma_2\n",
        "    t_sigma_term = - 0.5 * torch.log(2.0 * np.pi * t_sigma_2)\n",
        "\n",
        "    t_log_P_terms = t_sigma_term - (t_x_minus_mu_2 / t_denom)\n",
        "\n",
        "    # The sum is performed by a reduction in torch\n",
        "    # (since a vector goes in and a scalar comes out)\n",
        "    # but this is effectively the same as np.sum(...)\n",
        "    t_log_P = torch.sum(t_log_P_terms)\n",
        "\n",
        "    return t_log_P\n",
        "\n",
        "\n",
        "# Let's check again..\n",
        "print('Torch log p(X) = ', torch_gaussian_log_likelihood(t_x_n, t_mu, t_sigma))\n",
        "print('(using initial guesses for mu and sigma)\\n')\n",
        "\n",
        "print('Value from scipy stats package = ', check_value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pGLfC6bYQmal",
        "outputId": "4e1942e3-2c2f-48f0-fc50-39939a039caf"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Torch log p(X) =  tensor(-68.4921, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "(using initial guesses for mu and sigma)\n",
            "\n",
            "Value from scipy stats package =  -68.4921329611185\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-cND5yl7Rvg"
      },
      "source": [
        "### So now let's use the power of pytorch!!\n",
        "\n",
        "To perform optimisation we need to know the gradient of the log likelihood with respect to the particular parameters $\\mu$ and $\\sigma$.\n",
        "\n",
        "We know how to find these with torch using the backward from above!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "mRK7RHka7Rvg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5322788-8412-444e-e180-0000095b8395"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient wrt mu =  tensor(30.9592)\n",
            "Gradient wrt sigma =  tensor(80.2267, dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "t_log_P = torch_gaussian_log_likelihood(t_x_n, t_mu, t_sigma)\n",
        "\n",
        "t_log_P.backward()\n",
        "\n",
        "print('Gradient wrt mu = ', t_mu.grad)\n",
        "print('Gradient wrt sigma = ', t_sigma.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqOC4ujq7Rvh"
      },
      "source": [
        "Shall we check that result. Remember we have:\n",
        "\n",
        "\\begin{align}\n",
        "\\log  p(X)  &= \\sum_{n=0}^{N-1}\n",
        "    -\\frac{1}{2} \\log{\\left( 2\\pi\\sigma^2 \\right)}\n",
        "    -\\frac{(x_{n} - \\mu)^2}{2\\sigma^2} \\\\\n",
        "    &=  -\\frac{N}{2} \\log{\\left( 2\\pi\\sigma^2 \\right)}\n",
        "    - \\frac{1}{2\\sigma^2} \\sum_{n=0}^{N-1}\\left(x_{n} - \\mu\\right)^2\n",
        "\\end{align}\n",
        "\n",
        "So for $\\mu$ we have:\n",
        "\n",
        "\\begin{align}\n",
        "\\frac{\\partial \\log  p(X)}{\\partial \\mu}   \n",
        "    &= - 0\n",
        "    - \\frac{1}{2\\sigma^2} \\frac{\\partial}{\\partial \\mu}  \\sum_{n=0}^{N-1} \\left(x_{n} - \\mu\\right)^2 \\\\\n",
        "    &= - \\frac{1}{2\\sigma^2} \\sum_{n=0}^{N-1} \\frac{\\partial}{\\partial \\mu} \\left(x_{n} - \\mu\\right)^2 \\\\\n",
        "    &= - \\frac{1}{2\\sigma^2} \\sum_{n=0}^{N-1} 2 \\left(x_{n} - \\mu\\right) \\frac{\\partial}{\\partial \\mu}\\left(x_{n} - \\mu\\right)  \\\\\n",
        "    &= \\frac{1}{\\sigma^2} \\sum_{n=0}^{N-1} \\left(x_{n} - \\mu\\right)\n",
        "\\end{align}\n",
        "\n",
        "where we used the chain rule a number of times.."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "5fDDV9cD7Rvh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa0ff8a0-0ca3-4a9c-db56-439d72f8487b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Our analytic gradient wrt mu =  30.959211408943794\n",
            "Torch gradient wrt mu =  tensor(30.9592)\n",
            "\n",
            "Excellent! torch calculated the gradient for us :)\n"
          ]
        }
      ],
      "source": [
        "# numpy check of gradient wrt mu\n",
        "\n",
        "grad_mu_check = np.sum(x_n - mu_initial_guess) / \\\n",
        "                (sigma_initial_guess ** 2)\n",
        "\n",
        "print('Our analytic gradient wrt mu = ', grad_mu_check)\n",
        "\n",
        "print('Torch gradient wrt mu = ', t_mu.grad)\n",
        "\n",
        "assert(np.isclose(t_mu.grad.detach().numpy(), grad_mu_check))\n",
        "\n",
        "print('\\nExcellent! torch calculated the gradient for us :)')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wW9LE3_W7Rvj"
      },
      "source": [
        "## Everyone should now be in awe!\n",
        "\n",
        "This might seem like something trivial but hopefully you can see that actually quite a lot of maths and then coding went into determining the gradient.\n",
        "\n",
        "In fact, you can do the same to check the value for the gradient wrt $\\sigma^2$.\n",
        "\n",
        "When we calculated the result using the chain rule. Since torch built up a graph of the operations, it is able to apply the chain rule results for us automatically.\n",
        "\n",
        "This:\n",
        "\\begin{align}\n",
        "\\log  p(X)  &= \\sum_{n=0}^{N-1}\n",
        "    -\\frac{1}{2} \\log{\\left( 2\\pi\\sigma^2 \\right)}\n",
        "    -\\frac{(x_{n} - \\mu)^2}{2\\sigma^2}\n",
        "%    \\\\\n",
        "%    &=  -\\frac{N}{2} \\log{\\left( 2\\pi\\sigma^2 \\right)}\n",
        "%    - \\frac{1}{2\\sigma^2} \\sum_{n=0}^{N-1}\\left(x_{n} - \\mu\\right)^2\n",
        "\\end{align}\n",
        "has become a computational graph.\n",
        "\n",
        "For example, the `pow` operation represents $r = a^b$ for the inputs $a,b$ and result $r$. As above, torch then knows that $\\frac{\\partial r}{\\partial a} = b a^{b-1}$, and by chaining these operations together it can work backwards through the graph (from $\\log p(X)$ at the top to $\\mu$ at the bottom) to calculate the gradient.\n",
        "\n",
        "Therefore, the procedure when operating with torch is always the same. A **forward pass** can calculate the objective for the current set of parameters and then a **backwards pass** can calculate the gradients of an objective wrt any of the parameters."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simple gradient descent using these gradients..\n",
        "\n",
        "Let's use simple gradient descent to try to fit the values of our parameters to our data. Essentially, we start with some initial values and take a \"step\" in the direction of the (downhill) gradient in order to minimise the objective.\n",
        "\n",
        "In our case, the parameters that we want will maximise the log likelihood so the objective function we must use is to minimise the **negative** log likelihood.\n",
        "\n",
        "So the update rule will be:\n",
        "$$\n",
        "\\mu^{(k+1)} = \\mu^{(k)} - \\eta \\frac{\\partial}{\\partial \\mu} \\log p(\\mathbf{x})\n",
        "$$\n",
        "where $\\eta$ is some (small) step size and $k$ is the iteration index.\n",
        "\n",
        "Let us try to do this loop a few times:"
      ],
      "metadata": {
        "id": "nU0mHhKOTt8-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "number_of_iterations = 50\n",
        "step_size_eta = 1.0e-2\n",
        "\n",
        "# The data to fit to (NOTE: this is our constant data so no gradients required)\n",
        "t_x_n = torch.tensor(x_n)\n",
        "\n",
        "# Note: mu and sigma are now *variables* not constants!\n",
        "# We need to specify their data type and initial value..\n",
        "t_mu = torch.tensor(mu_initial_guess, requires_grad=True)\n",
        "t_sigma = torch.tensor(sigma_initial_guess, requires_grad=True)\n",
        "\n",
        "for iteration in range(number_of_iterations + 1):\n",
        "    # Perform the forward pass, calculate - log p(x)\n",
        "    t_neg_log_likelihood = -1.0 * torch_gaussian_log_likelihood(t_x_n, t_mu, t_sigma)\n",
        "\n",
        "    # Perform the backwards pass to get the gradients\n",
        "    t_neg_log_likelihood.backward()\n",
        "\n",
        "    # Temporarily disable gradient computations so that we can update the\n",
        "    # parameter values (we don't want to differentiate the update!)..\n",
        "    with torch.no_grad():\n",
        "        # Update the parameters based on the step size..\n",
        "        t_mu -= step_size_eta * t_mu.grad\n",
        "        t_sigma -= step_size_eta * t_sigma.grad\n",
        "\n",
        "        # IMPORTANT: Clear the gradients for next time..\n",
        "        t_mu.grad.data.zero_()\n",
        "        t_sigma.grad.data.zero_()\n",
        "\n",
        "    # Print out the current values\n",
        "    if iteration % 10 == 0:\n",
        "        print('Iter %04d, NLL %0.2e, mu %.4f, sigma %.4f' %\n",
        "              (iteration, t_neg_log_likelihood.detach().numpy(), t_mu, t_sigma))\n",
        "\n",
        "\n",
        "print('\\nAfter optimisation:')\n",
        "print('Torch mu = ', t_mu)\n",
        "print('Torch sigma = ', t_sigma)\n",
        "\n",
        "print('\\nAnalytic estimates:')\n",
        "print('Estimated mu = ', np.mean(x_n))\n",
        "print('Estimated std = ', np.std(x_n))\n",
        "\n",
        "print('\\nGround truth values:')\n",
        "print('True mu = ', mu_true)\n",
        "print('True sigma = ', sigma_true)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IyITZL-ZTuVw",
        "outputId": "137b9fc2-5e47-4f49-845a-256ce38b9b07"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 0000, NLL 6.24e+01, mu 1.3014, sigma 1.6803\n",
            "Iter 0010, NLL 3.78e+01, mu 1.9082, sigma 1.6846\n",
            "Iter 0020, NLL 3.64e+01, mu 2.2366, sigma 1.5469\n",
            "Iter 0030, NLL 3.60e+01, mu 2.3990, sigma 1.4806\n",
            "Iter 0040, NLL 3.60e+01, mu 2.4661, sigma 1.4635\n",
            "Iter 0050, NLL 3.59e+01, mu 2.4917, sigma 1.4602\n",
            "\n",
            "After optimisation:\n",
            "Torch mu =  tensor(2.4917, requires_grad=True)\n",
            "Torch sigma =  tensor(1.4602, dtype=torch.float64, requires_grad=True)\n",
            "\n",
            "Analytic estimates:\n",
            "Estimated mu =  2.5070199462302023\n",
            "Estimated std =  1.4595466199983618\n",
            "\n",
            "Ground truth values:\n",
            "True mu =  2.5\n",
            "True sigma =  1.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Great - we can run an optimisation that automatically calculates the gradients!\n",
        "\n",
        "So we now have everything coming together to perform a nummerical optimisation where we can perform gradient descent without having to write any code to calculate the gradients ourselves (yay!!).\n",
        "\n",
        "The final stage is that there were a few technical gotchas in there around dealing with the parameter gradients and updating them (i.e. we had to temporaily suspend gradient calculation and ensure that we zeroed the gradient datastructures for each parameter.\n",
        "\n",
        "Torch provides a nicer way to modularise this process into an object (or class) in python that provides a nicer interfact. Each module has a set of parameters to be optimised and a forward operation to be performed on data. The autograd operations will then take care of performing the backward operation and an optimiser can be called to control how the parameters are updated (e.g. something more complicated than simple gradient descent).\n",
        "\n",
        "Let's wrap up our code in this interface.\n"
      ],
      "metadata": {
        "id": "r_J7ELAtaFh-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Putting models into modules..\n",
        "\n",
        "Torch has a paradigm to make this procedure easy to work with based on deriving your own class based on a `module` that keeps parameters and the forward pass of the model together to allow easy optimisation."
      ],
      "metadata": {
        "id": "5dS4vPaJTYcp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create our own class derived from the torch module..\n",
        "class MaximumLikelihoodGaussianModel(torch.nn.Module):\n",
        "    # We must initialise our model - we specify our initial guesses for the\n",
        "    # parameters..\n",
        "    def __init__(self, mu_initial_guess, sigma_initial_guess):\n",
        "        # Call the constructor for the torch.nn.Module super class..\n",
        "        super().__init__()\n",
        "\n",
        "        # We use the Parameter class (rather than tensors) for the module\n",
        "        # but these behave in the same way..\n",
        "        self.t_mu = torch.nn.Parameter(torch.tensor(mu_initial_guess))\n",
        "        self.t_sigma = torch.nn.Parameter(torch.tensor(sigma_initial_guess))\n",
        "\n",
        "    # This defines the forward operation on some data passed in\n",
        "    def forward(self, t_x_n):\n",
        "\n",
        "        # We will copy in the code from torch_gaussian_log_likelihood..\n",
        "\n",
        "        # Note: this step is important - don't use t_sigma directly!!\n",
        "        t_sigma_2 = self.t_sigma ** 2.0\n",
        "\n",
        "        # Calculate log p(X) terms..\n",
        "\n",
        "        t_x_minus_mu_2 = (t_x_n - self.t_mu) ** 2.0\n",
        "        t_denom = 2.0 * t_sigma_2\n",
        "        t_sigma_term = - 0.5 * torch.log(2.0 * np.pi * t_sigma_2)\n",
        "\n",
        "        t_log_P_terms = t_sigma_term - (t_x_minus_mu_2 / t_denom)\n",
        "\n",
        "        # The sum is performed by a reduction in torch\n",
        "        # (since a vector goes in and a scalar comes out)\n",
        "        # but this is effectively the same as np.sum(...)\n",
        "        t_log_P = torch.sum(t_log_P_terms)\n",
        "\n",
        "        # Remember to take the negative to return the negative log likelihood..\n",
        "        return -1.0 * t_log_P"
      ],
      "metadata": {
        "id": "hoaYa2SnbXvL"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Now we can optimise our custom module\n",
        "\n",
        "We can now use the standard optimisation approach for torch using our custom module. The steps are:\n",
        "- Define an instance of our module\n",
        "- Define an optimiser\n",
        "- Loop for each iteration:\n",
        "    - Zero the gradients\n",
        "    - Perform the forward pass\n",
        "    - Perform the backward pass\n",
        "    - Take an optimiser step"
      ],
      "metadata": {
        "id": "k4M2qt4DdI-S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "number_of_iterations = 50\n",
        "# Note the step size is also referred to as the learning rate..\n",
        "learning_rate = 1.0e-2\n",
        "\n",
        "# The data to fit to (NOTE: this is our constant data so no gradients required)\n",
        "t_x_n = torch.tensor(x_n)\n",
        "\n",
        "# Create our model - it will initialise the paramters appropriately\n",
        "gaussian_model = MaximumLikelihoodGaussianModel(mu_initial_guess, sigma_initial_guess)\n",
        "gaussian_model.train()\n",
        "\n",
        "# Create an optimiser for our model, the model has a datastructure of all\n",
        "# the parameters to optimise that we will pass in (along with the learning rate)\n",
        "optimizer = torch.optim.SGD(gaussian_model.parameters(), lr=learning_rate)\n",
        "\n",
        "for iteration in range(number_of_iterations + 1):\n",
        "    # Perform the forward pass by calling the model with the data..\n",
        "    t_neg_log_likelihood = gaussian_model(t_x_n)\n",
        "\n",
        "    # Clear the gradients..\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Perform the backwards pass to calculate the gradients..\n",
        "    t_neg_log_likelihood.backward()\n",
        "\n",
        "    # Update the parameters via the optimiser..\n",
        "    optimizer.step()\n",
        "\n",
        "    # Print out the current values\n",
        "    if iteration % 10 == 0:\n",
        "        print('Iter %04d, NLL %0.2e, mu %.4f, sigma %.4f' %\n",
        "              (iteration, t_neg_log_likelihood.item(),\n",
        "               gaussian_model.t_mu, gaussian_model.t_sigma))\n",
        "\n",
        "\n",
        "print('\\nAfter optimisation:')\n",
        "print('Torch mu = ', gaussian_model.t_mu.item())\n",
        "print('Torch sigma = ', gaussian_model.t_sigma.item())\n",
        "\n",
        "print('\\nAnalytic estimates:')\n",
        "print('Estimated mu = ', np.mean(x_n))\n",
        "print('Estimated std = ', np.std(x_n))\n",
        "\n",
        "print('\\nGround truth values:')\n",
        "print('True mu = ', mu_true)\n",
        "print('True sigma = ', sigma_true)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15AFQLIbdJT6",
        "outputId": "a885565c-5085-42f4-980c-348a1c9edcab"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 0000, NLL 6.24e+01, mu 1.3014, sigma 1.6803\n",
            "Iter 0010, NLL 3.78e+01, mu 1.9082, sigma 1.6846\n",
            "Iter 0020, NLL 3.64e+01, mu 2.2366, sigma 1.5469\n",
            "Iter 0030, NLL 3.60e+01, mu 2.3990, sigma 1.4806\n",
            "Iter 0040, NLL 3.60e+01, mu 2.4661, sigma 1.4635\n",
            "Iter 0050, NLL 3.59e+01, mu 2.4917, sigma 1.4602\n",
            "\n",
            "After optimisation:\n",
            "Torch mu =  2.4916980266571045\n",
            "Torch sigma =  1.4602219137654822\n",
            "\n",
            "Analytic estimates:\n",
            "Estimated mu =  2.5070199462302023\n",
            "Estimated std =  1.4595466199983618\n",
            "\n",
            "Ground truth values:\n",
            "True mu =  2.5\n",
            "True sigma =  1.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Great - let's visualise our working model..\n",
        "\n",
        "Our new torch module allows us to perform the optimisation of our parameters using a standard approach (we can change the model and the rest of the code is unaltered).\n",
        "\n",
        "**We can also visualise the computational graph created by our model with the follow code:**"
      ],
      "metadata": {
        "id": "nxF7W1PWm-e6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "make_dot(gaussian_model(t_x_n), params=dict(gaussian_model.named_parameters()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        },
        "id": "AN8FbjhTm_M8",
        "outputId": "ceed8d50-7bf8-4758-81fd-f25aa0b41b10"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.43.0 (0)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"317pt\" height=\"545pt\"\n viewBox=\"0.00 0.00 317.00 545.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 541)\">\n<title>%3</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-541 313,-541 313,4 -4,4\"/>\n<!-- 135606290522864 -->\n<g id=\"node1\" class=\"node\">\n<title>135606290522864</title>\n<polygon fill=\"#caff70\" stroke=\"black\" points=\"237.5,-31 183.5,-31 183.5,0 237.5,0 237.5,-31\"/>\n<text text-anchor=\"middle\" x=\"210.5\" y=\"-7\" font-family=\"monospace\" font-size=\"10.00\"> ()</text>\n</g>\n<!-- 135606290614640 -->\n<g id=\"node2\" class=\"node\">\n<title>135606290614640</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"255,-86 166,-86 166,-67 255,-67 255,-86\"/>\n<text text-anchor=\"middle\" x=\"210.5\" y=\"-74\" font-family=\"monospace\" font-size=\"10.00\">MulBackward0</text>\n</g>\n<!-- 135606290614640&#45;&gt;135606290522864 -->\n<g id=\"edge16\" class=\"edge\">\n<title>135606290614640&#45;&gt;135606290522864</title>\n<path fill=\"none\" stroke=\"black\" d=\"M210.5,-66.79C210.5,-60.07 210.5,-50.4 210.5,-41.34\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"214,-41.19 210.5,-31.19 207,-41.19 214,-41.19\"/>\n</g>\n<!-- 135606290614352 -->\n<g id=\"node3\" class=\"node\">\n<title>135606290614352</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"255,-141 166,-141 166,-122 255,-122 255,-141\"/>\n<text text-anchor=\"middle\" x=\"210.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\">SumBackward0</text>\n</g>\n<!-- 135606290614352&#45;&gt;135606290614640 -->\n<g id=\"edge1\" class=\"edge\">\n<title>135606290614352&#45;&gt;135606290614640</title>\n<path fill=\"none\" stroke=\"black\" d=\"M210.5,-121.75C210.5,-114.8 210.5,-104.85 210.5,-96.13\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"214,-96.09 210.5,-86.09 207,-96.09 214,-96.09\"/>\n</g>\n<!-- 135606290614400 -->\n<g id=\"node4\" class=\"node\">\n<title>135606290614400</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"255,-196 166,-196 166,-177 255,-177 255,-196\"/>\n<text text-anchor=\"middle\" x=\"210.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\">SubBackward0</text>\n</g>\n<!-- 135606290614400&#45;&gt;135606290614352 -->\n<g id=\"edge2\" class=\"edge\">\n<title>135606290614400&#45;&gt;135606290614352</title>\n<path fill=\"none\" stroke=\"black\" d=\"M210.5,-176.75C210.5,-169.8 210.5,-159.85 210.5,-151.13\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"214,-151.09 210.5,-141.09 207,-151.09 214,-151.09\"/>\n</g>\n<!-- 135606290613392 -->\n<g id=\"node5\" class=\"node\">\n<title>135606290613392</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"300,-251 211,-251 211,-232 300,-232 300,-251\"/>\n<text text-anchor=\"middle\" x=\"255.5\" y=\"-239\" font-family=\"monospace\" font-size=\"10.00\">MulBackward0</text>\n</g>\n<!-- 135606290613392&#45;&gt;135606290614400 -->\n<g id=\"edge3\" class=\"edge\">\n<title>135606290613392&#45;&gt;135606290614400</title>\n<path fill=\"none\" stroke=\"black\" d=\"M248.07,-231.75C241.65,-224.18 232.19,-213.05 224.38,-203.84\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"226.93,-201.45 217.79,-196.09 221.6,-205.98 226.93,-201.45\"/>\n</g>\n<!-- 135606290613440 -->\n<g id=\"node6\" class=\"node\">\n<title>135606290613440</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"309,-306 220,-306 220,-287 309,-287 309,-306\"/>\n<text text-anchor=\"middle\" x=\"264.5\" y=\"-294\" font-family=\"monospace\" font-size=\"10.00\">LogBackward0</text>\n</g>\n<!-- 135606290613440&#45;&gt;135606290613392 -->\n<g id=\"edge4\" class=\"edge\">\n<title>135606290613440&#45;&gt;135606290613392</title>\n<path fill=\"none\" stroke=\"black\" d=\"M263.01,-286.75C261.83,-279.8 260.14,-269.85 258.66,-261.13\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"262.08,-260.36 256.96,-251.09 255.18,-261.53 262.08,-260.36\"/>\n</g>\n<!-- 135606290613872 -->\n<g id=\"node7\" class=\"node\">\n<title>135606290613872</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"309,-361 220,-361 220,-342 309,-342 309,-361\"/>\n<text text-anchor=\"middle\" x=\"264.5\" y=\"-349\" font-family=\"monospace\" font-size=\"10.00\">MulBackward0</text>\n</g>\n<!-- 135606290613872&#45;&gt;135606290613440 -->\n<g id=\"edge5\" class=\"edge\">\n<title>135606290613872&#45;&gt;135606290613440</title>\n<path fill=\"none\" stroke=\"black\" d=\"M264.5,-341.75C264.5,-334.8 264.5,-324.85 264.5,-316.13\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"268,-316.09 264.5,-306.09 261,-316.09 268,-316.09\"/>\n</g>\n<!-- 135606290614160 -->\n<g id=\"node8\" class=\"node\">\n<title>135606290614160</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"261,-416 172,-416 172,-397 261,-397 261,-416\"/>\n<text text-anchor=\"middle\" x=\"216.5\" y=\"-404\" font-family=\"monospace\" font-size=\"10.00\">PowBackward0</text>\n</g>\n<!-- 135606290614160&#45;&gt;135606290613872 -->\n<g id=\"edge6\" class=\"edge\">\n<title>135606290614160&#45;&gt;135606290613872</title>\n<path fill=\"none\" stroke=\"black\" d=\"M224.43,-396.75C231.35,-389.11 241.57,-377.82 249.95,-368.56\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"252.6,-370.85 256.72,-361.09 247.41,-366.15 252.6,-370.85\"/>\n</g>\n<!-- 135606290613296 -->\n<g id=\"node16\" class=\"node\">\n<title>135606290613296</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"202,-361 113,-361 113,-342 202,-342 202,-361\"/>\n<text text-anchor=\"middle\" x=\"157.5\" y=\"-349\" font-family=\"monospace\" font-size=\"10.00\">MulBackward0</text>\n</g>\n<!-- 135606290614160&#45;&gt;135606290613296 -->\n<g id=\"edge15\" class=\"edge\">\n<title>135606290614160&#45;&gt;135606290613296</title>\n<path fill=\"none\" stroke=\"black\" d=\"M207.02,-396.98C198.3,-389.15 185.16,-377.34 174.6,-367.86\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"176.93,-365.25 167.15,-361.17 172.25,-370.46 176.93,-365.25\"/>\n</g>\n<!-- 135606290617232 -->\n<g id=\"node9\" class=\"node\">\n<title>135606290617232</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"267,-471 166,-471 166,-452 267,-452 267,-471\"/>\n<text text-anchor=\"middle\" x=\"216.5\" y=\"-459\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 135606290617232&#45;&gt;135606290614160 -->\n<g id=\"edge7\" class=\"edge\">\n<title>135606290617232&#45;&gt;135606290614160</title>\n<path fill=\"none\" stroke=\"black\" d=\"M216.5,-451.75C216.5,-444.8 216.5,-434.85 216.5,-426.13\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"220,-426.09 216.5,-416.09 213,-426.09 220,-426.09\"/>\n</g>\n<!-- 135606290630832 -->\n<g id=\"node10\" class=\"node\">\n<title>135606290630832</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"246,-537 187,-537 187,-507 246,-507 246,-537\"/>\n<text text-anchor=\"middle\" x=\"216.5\" y=\"-525\" font-family=\"monospace\" font-size=\"10.00\">t_sigma</text>\n<text text-anchor=\"middle\" x=\"216.5\" y=\"-514\" font-family=\"monospace\" font-size=\"10.00\"> ()</text>\n</g>\n<!-- 135606290630832&#45;&gt;135606290617232 -->\n<g id=\"edge8\" class=\"edge\">\n<title>135606290630832&#45;&gt;135606290617232</title>\n<path fill=\"none\" stroke=\"black\" d=\"M216.5,-506.84C216.5,-499.21 216.5,-489.7 216.5,-481.45\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"220,-481.27 216.5,-471.27 213,-481.27 220,-481.27\"/>\n</g>\n<!-- 135606290614736 -->\n<g id=\"node11\" class=\"node\">\n<title>135606290614736</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"202,-306 113,-306 113,-287 202,-287 202,-306\"/>\n<text text-anchor=\"middle\" x=\"157.5\" y=\"-294\" font-family=\"monospace\" font-size=\"10.00\">DivBackward0</text>\n</g>\n<!-- 135606290614736&#45;&gt;135606290614400 -->\n<g id=\"edge9\" class=\"edge\">\n<title>135606290614736&#45;&gt;135606290614400</title>\n<path fill=\"none\" stroke=\"black\" d=\"M161.84,-286.66C170.54,-268.93 190.27,-228.73 201.76,-205.32\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"204.99,-206.68 206.25,-196.16 198.7,-203.59 204.99,-206.68\"/>\n</g>\n<!-- 135606290613632 -->\n<g id=\"node12\" class=\"node\">\n<title>135606290613632</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"95,-361 6,-361 6,-342 95,-342 95,-361\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-349\" font-family=\"monospace\" font-size=\"10.00\">PowBackward0</text>\n</g>\n<!-- 135606290613632&#45;&gt;135606290614736 -->\n<g id=\"edge10\" class=\"edge\">\n<title>135606290613632&#45;&gt;135606290614736</title>\n<path fill=\"none\" stroke=\"black\" d=\"M67.69,-341.98C84.75,-333.54 111.13,-320.47 130.9,-310.68\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"132.59,-313.75 140,-306.17 129.48,-307.47 132.59,-313.75\"/>\n</g>\n<!-- 135606290614976 -->\n<g id=\"node13\" class=\"node\">\n<title>135606290614976</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"95,-416 6,-416 6,-397 95,-397 95,-416\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-404\" font-family=\"monospace\" font-size=\"10.00\">SubBackward0</text>\n</g>\n<!-- 135606290614976&#45;&gt;135606290613632 -->\n<g id=\"edge11\" class=\"edge\">\n<title>135606290614976&#45;&gt;135606290613632</title>\n<path fill=\"none\" stroke=\"black\" d=\"M50.5,-396.75C50.5,-389.8 50.5,-379.85 50.5,-371.13\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"54,-371.09 50.5,-361.09 47,-371.09 54,-371.09\"/>\n</g>\n<!-- 135606290617472 -->\n<g id=\"node14\" class=\"node\">\n<title>135606290617472</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"101,-471 0,-471 0,-452 101,-452 101,-471\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-459\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 135606290617472&#45;&gt;135606290614976 -->\n<g id=\"edge12\" class=\"edge\">\n<title>135606290617472&#45;&gt;135606290614976</title>\n<path fill=\"none\" stroke=\"black\" d=\"M50.5,-451.75C50.5,-444.8 50.5,-434.85 50.5,-426.13\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"54,-426.09 50.5,-416.09 47,-426.09 54,-426.09\"/>\n</g>\n<!-- 135606290630672 -->\n<g id=\"node15\" class=\"node\">\n<title>135606290630672</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"77.5,-537 23.5,-537 23.5,-507 77.5,-507 77.5,-537\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-525\" font-family=\"monospace\" font-size=\"10.00\">t_mu</text>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-514\" font-family=\"monospace\" font-size=\"10.00\"> ()</text>\n</g>\n<!-- 135606290630672&#45;&gt;135606290617472 -->\n<g id=\"edge13\" class=\"edge\">\n<title>135606290630672&#45;&gt;135606290617472</title>\n<path fill=\"none\" stroke=\"black\" d=\"M50.5,-506.84C50.5,-499.21 50.5,-489.7 50.5,-481.45\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"54,-481.27 50.5,-471.27 47,-481.27 54,-481.27\"/>\n</g>\n<!-- 135606290613296&#45;&gt;135606290614736 -->\n<g id=\"edge14\" class=\"edge\">\n<title>135606290613296&#45;&gt;135606290614736</title>\n<path fill=\"none\" stroke=\"black\" d=\"M157.5,-341.75C157.5,-334.8 157.5,-324.85 157.5,-316.13\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"161,-316.09 157.5,-306.09 154,-316.09 161,-316.09\"/>\n</g>\n</g>\n</svg>\n",
            "text/plain": [
              "<graphviz.graphs.Digraph at 0x7b554cc808e0>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This shows us all the functions we would have to have implemented in order to calculate the gradients in the backward pass - we got all these for free using torch instead of numpy!!"
      ],
      "metadata": {
        "id": "sT4hecTCncE5"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FN39WiDJ7Rvj"
      },
      "source": [
        "## But the fun doesn't end here!\n",
        "\n",
        "We can now run the same code again with different data just by changing the data we pass in to the model. This is how minibatching can be performed where we use a different subset of the data at each iteration (if we have very large datasets) to estimate the gradients to perform **stochastic gradient descent**.\n",
        "\n",
        "Let's try with a larger dataset..\n",
        "\n",
        "#### More information on dataset loading:\n",
        "\n",
        "[Datasets and Dataloaders](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "N_bigger = 1000\n",
        "\n",
        "number_of_iterations = 50\n",
        "# Note the step size is also referred to as the learning rate..\n",
        "learning_rate = 1.0e-3\n",
        "\n",
        "x_bigger = np.random.normal(mu_true, sigma_true, N_bigger)\n",
        "t_x_n = torch.tensor(x_bigger)\n",
        "\n",
        "# Create our model - it will initialise the paramters appropriately\n",
        "gaussian_model = MaximumLikelihoodGaussianModel(mu_initial_guess, sigma_initial_guess)\n",
        "gaussian_model.train()\n",
        "\n",
        "# Create an optimiser for our model, the model has a datastructure of all\n",
        "# the parameters to optimise that we will pass in (along with the learning rate)\n",
        "optimizer = torch.optim.SGD(gaussian_model.parameters(), lr=learning_rate)\n",
        "\n",
        "print([a for a in gaussian_model.parameters()])\n",
        "\n",
        "for iteration in range(number_of_iterations + 1):\n",
        "    # Perform the forward pass by calling the model with the data..\n",
        "    t_neg_log_likelihood = gaussian_model(t_x_n)\n",
        "\n",
        "    # Clear the gradients..\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Perform the backwards pass to calculate the gradients..\n",
        "    t_neg_log_likelihood.backward()\n",
        "\n",
        "    # Update the parameters via the optimiser..\n",
        "    optimizer.step()\n",
        "\n",
        "    # Print out the current values\n",
        "    if iteration % 10 == 0:\n",
        "        print('Iter %04d, NLL %0.2e, mu %.4f, sigma %.4f' %\n",
        "              (iteration, t_neg_log_likelihood.item(),\n",
        "               gaussian_model.t_mu, gaussian_model.t_sigma))\n",
        "\n",
        "\n",
        "print('\\nAfter optimisation:')\n",
        "print('Torch mu = ', gaussian_model.t_mu.item())\n",
        "print('Torch sigma = ', gaussian_model.t_sigma.item())\n",
        "\n",
        "print('\\nAnalytic estimates:')\n",
        "print('Estimated mu = ', np.mean(x_n))\n",
        "print('Estimated std = ', np.std(x_n))\n",
        "\n",
        "print('\\nGround truth values:')\n",
        "print('True mu = ', mu_true)\n",
        "print('True sigma = ', sigma_true)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3S3awmJhqQr",
        "outputId": "812a49d4-4ce8-475f-e613-87581be97d50"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Parameter containing:\n",
            "tensor(1., requires_grad=True), Parameter containing:\n",
            "tensor(1., dtype=torch.float64, requires_grad=True)]\n",
            "Iter 0000, NLL 3.30e+03, mu 2.5742, sigma 4.7542\n",
            "Iter 0010, NLL 2.09e+03, mu 2.5742, sigma 2.5471\n",
            "Iter 0020, NLL 1.83e+03, mu 2.5742, sigma 1.5087\n",
            "Iter 0030, NLL 1.83e+03, mu 2.5742, sigma 1.5087\n",
            "Iter 0040, NLL 1.83e+03, mu 2.5742, sigma 1.5087\n",
            "Iter 0050, NLL 1.83e+03, mu 2.5742, sigma 1.5087\n",
            "\n",
            "After optimisation:\n",
            "Torch mu =  2.5741844177246094\n",
            "Torch sigma =  1.5086874747771968\n",
            "\n",
            "Analytic estimates:\n",
            "Estimated mu =  2.5070199462302023\n",
            "Estimated std =  1.4595466199983618\n",
            "\n",
            "Ground truth values:\n",
            "True mu =  2.5\n",
            "True sigma =  1.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNcBcaXZ7Rvp"
      },
      "source": [
        "## All sorts of more advanced topics\n",
        "\n",
        "- Visualise parts of computation (e.g. Tensorboard)\n",
        "- Reusable components (e.g. modules for neural networks / classifiers / etc..)\n",
        "- Run computations on the GPU instead of the CPU (often faster)\n",
        "- Easy to scale; can distribute computations over an entire cluster!\n",
        "\n",
        "#### More references:\n",
        "\n",
        "[PyTorch Tutorials](https://pytorch.org/tutorials/index.html)\n",
        "\n",
        "[PyTorch with Examples](https://pytorch.org/tutorials/beginner/pytorch_with_examples.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "abiEL3jB6G18"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f3in511lmt0G"
      },
      "execution_count": 18,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "PyTorch Example.ipynb",
      "provenance": []
    },
    "hide_input": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}